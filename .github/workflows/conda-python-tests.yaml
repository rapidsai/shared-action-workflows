on:
  workflow_call:
    inputs:
      build_type:
        required: true
        type: string
      branch:
        type: string
      date:
        type: string
      sha:
        type: string
      repo:
        type: string
      script:
        type: string
        default: "ci/test_python.sh"
      run_codecov:
        type: boolean
        default: true
      matrix_filter:
        type: string
        default: "."
      container-options:
        required: false
        type: string
        default: "-e _NOOP"
      # telemetry settings: Destination to send telemetry to
      default_endpoint:
        type: string
      # defaults to <default_endpoint>/v1/traces
      # Change it if you want to send to a different host or port number
      traces_endpoint:
        type: string
      # defaults to <default_endpoint>/v1/metrics
      # Change it if you want to send to a different host or port number
      metrics_endpoint:
        type: string
      # defaults to <default_endpoint>/v1/logs
      # Change it if you want to send to a different host or port number
      logs_endpoint:
        type: string
      traceparent:
        type: string
        description: |
            Opentelemetry traceparent. Format is described in https://medium.com/@mesutatasoy/understanding-traceparent-and-microservices-in-opentelemetry-notepad-series-7-de5c16bf6462
            Generally, 00-<trace_id 32 chars>-<span_id 16 chars>-01

defaults:
  run:
    shell: bash

permissions:
  actions: read
  checks: none
  contents: read
  deployments: none
  discussions: none
  id-token: write
  issues: none
  packages: read
  pages: none
  pull-requests: read
  repository-projects: none
  security-events: none
  statuses: none

env:
  TOP_LEVEL_TRACEPARENT: ${{ inputs.traceparent }}
  OTEL_EXPORTER_OTLP_ENDPOINT: "${{ inputs.default_endpoint }}"
  OTEL_EXPORTER_OTLP_TRACES_ENDPOINT: "${{ inputs.traces_endpoint }}"
  OTEL_EXPORTER_OTLP_METRICS_ENDPOINT: "${{ inputs.metrics_endpoint }}"
  OTEL_EXPORTER_OTLP_LOGS_ENDPOINT: "${{ inputs.logs_endpoint }}"
  OTEL_EXPORTER_OTLP_PROTOCOL: "http/protobuf"
  OTEL_EXPORTER_OTLP_HEADERS: ${{ secrets.OTEL_EXPORTER_OTLP_HEADERS }}
  OTEL_EXPORTER_OTLP_CERTIFICATE: "/tmp/certs/ca.crt"
  OTEL_EXPORTER_OTLP_CLIENT_CERTIFICATE: "/tmp/certs/client.crt"
  OTEL_EXPORTER_OTLP_CLIENT_KEY: "/tmp/certs/client.key"

jobs:
  compute-matrix:
    runs-on: ubuntu-latest
    env:
      BUILD_TYPE: ${{ inputs.build_type }}
    outputs:
      MATRIX: ${{ steps.compute-matrix.outputs.MATRIX }}
    steps:
      - name: Validate Test Type
        run: |
          if [[ "$BUILD_TYPE" != "pull-request" ]] && [[ "$BUILD_TYPE" != "nightly" ]]; then
              echo "Invalid build type! Must be 'nightly' or 'pull-request'."
              exit 1
          fi
      - name: Compute Python Test Matrix
        id: compute-matrix
        run: |
          set -eo pipefail

          # please keep the matrices sorted in ascending order by the following:
          #
          #     [ARCH, PY_VER, CUDA_VER, LINUX_VER, GPU, DRIVER, DEPENDENCIES]
          #
          export MATRICES="
            pull-request:
              # amd64
              - { ARCH: 'amd64', PY_VER: '3.10', CUDA_VER: '11.8.0', LINUX_VER: 'rockylinux8', GPU: 'v100', DRIVER: 'earliest', DEPENDENCIES: 'oldest' }
              - { ARCH: 'amd64', PY_VER: '3.12', CUDA_VER: '12.5.1', LINUX_VER: 'ubuntu22.04', GPU: 'v100', DRIVER: 'latest',   DEPENDENCIES: 'latest' }
              # arm64
              - { ARCH: 'arm64', PY_VER: '3.11', CUDA_VER: '12.0.1', LINUX_VER: 'ubuntu20.04', GPU: 'a100', DRIVER: 'latest',   DEPENDENCIES: 'latest' }
            nightly:
              # amd64
              - { ARCH: 'amd64', PY_VER: '3.10', CUDA_VER: '11.4.3', LINUX_VER: 'rockylinux8', GPU: 'v100', DRIVER: 'earliest', DEPENDENCIES: 'oldest' }
              - { ARCH: 'amd64', PY_VER: '3.10', CUDA_VER: '11.8.0', LINUX_VER: 'ubuntu22.04', GPU: 'v100', DRIVER: 'latest',   DEPENDENCIES: 'latest' }
              - { ARCH: 'amd64', PY_VER: '3.11', CUDA_VER: '12.0.1', LINUX_VER: 'rockylinux8', GPU: 'v100', DRIVER: 'latest',   DEPENDENCIES: 'latest' }
              - { ARCH: 'amd64', PY_VER: '3.12', CUDA_VER: '12.5.1', LINUX_VER: 'ubuntu22.04', GPU: 'v100', DRIVER: 'latest',   DEPENDENCIES: 'latest' }
              # arm64
              - { ARCH: 'arm64', PY_VER: '3.10', CUDA_VER: '12.2.2', LINUX_VER: 'ubuntu22.04', GPU: 'a100', DRIVER: 'latest',   DEPENDENCIES: 'oldest' }
              - { ARCH: 'arm64', PY_VER: '3.11', CUDA_VER: '11.8.0', LINUX_VER: 'ubuntu22.04', GPU: 'a100', DRIVER: 'latest',   DEPENDENCIES: 'latest' }
              - { ARCH: 'arm64', PY_VER: '3.12', CUDA_VER: '12.5.1', LINUX_VER: 'rockylinux8', GPU: 'a100', DRIVER: 'latest',   DEPENDENCIES: 'latest' }
          "

          TEST_MATRIX=$(yq -n 'env(MATRICES) | .[strenv(BUILD_TYPE)]')
          export TEST_MATRIX

          MATRIX="$(
            yq -n -o json 'env(TEST_MATRIX)' | \
            jq -c '${{ inputs.matrix_filter }} | if (. | length) > 0 then {include: .} else "Error: Empty matrix\n" | halt_error(1) end'
          )"

          echo "MATRIX=${MATRIX}" | tee --append "${GITHUB_OUTPUT}"
  tests:
    name: ${{ matrix.CUDA_VER }}, ${{ matrix.PY_VER }}, ${{ matrix.ARCH }}, ${{ matrix.LINUX_VER }}, ${{ matrix.GPU }}, ${{ matrix.DRIVER }}-driver, ${{ matrix.DEPENDENCIES }}-deps
    needs: compute-matrix
    strategy:
      fail-fast: false
      matrix: ${{ fromJSON(needs.compute-matrix.outputs.MATRIX) }}
    runs-on: "linux-${{ matrix.ARCH }}-gpu-${{ matrix.GPU }}-${{ matrix.DRIVER }}-1"
    env:
      RAPIDS_ARTIFACTS_DIR: ${{ github.workspace }}/artifacts
      RAPIDS_COVERAGE_DIR: ${{ github.workspace }}/coverage-results
      RAPIDS_DEPENDENCIES: ${{ matrix.DEPENDENCIES }}
      RAPIDS_TESTS_DIR: ${{ github.workspace }}/test-results
    container:
      image: rapidsai/ci-conda:cuda${{ matrix.CUDA_VER }}-${{ matrix.LINUX_VER }}-py${{ matrix.PY_VER }}
      options: ${{ inputs.container-options }}
      env:
        RAPIDS_BUILD_TYPE: ${{ inputs.build_type }}
        NVIDIA_VISIBLE_DEVICES: ${{ env.NVIDIA_VISIBLE_DEVICES }}
    steps:
      # Temporary until ci-imgs build with
      # https://github.com/rapidsai/gha-tools/commit/8bd8fca71b5fae38b1493c547d15e73da40b32e1#diff-f1f054b2906bfd36ad706ed2fa6aa028fa529e65b25167e4ca7ca45546d59ed8R14
      # is available. The PR is merged, but at time of writing, no ci-imgs builds have been released to pick it up.
      - name: Download gha-tools with git clone
        run: |
            git clone https://github.com/msarahan/gha-tools.git -b add-telemetry-traceparent-scripts /tmp/gha-tools
            echo "/tmp/gha-tools/tools" >> "${GITHUB_PATH}"

      - name: Telemetry setup
        id: job-traceparent
        uses: rapidsai/shared-actions/telemetry-traceparent@add-telemetry

      - name: Write certificate files for mTLS
        run: |
          mkdir -p /tmp/certs
          cat << EOF > ${OTEL_EXPORTER_OTLP_CERTIFICATE}
          ${{ secrets.OTEL_EXPORTER_OTLP_CA_CERTIFICATE }}
          EOF
          cat << EOF > ${OTEL_EXPORTER_OTLP_CLIENT_CERTIFICATE}
          ${{ secrets.OTEL_EXPORTER_OTLP_CLIENT_CERTIFICATE }}
          EOF
          cat << EOF > ${OTEL_EXPORTER_OTLP_CLIENT_KEY}
          ${{ secrets.OTEL_EXPORTER_OTLP_CLIENT_KEY }}
          EOF

      - uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ vars.AWS_ROLE_ARN }}
          aws-region: ${{ vars.AWS_REGION }}
          role-duration-seconds: 43200 # 12h
      - uses: actions/checkout@v4
        with:
          repository: ${{ inputs.repo }}
          ref: ${{ inputs.sha }}
          fetch-depth: 0
      - name: Standardize repository information
        run: |
          echo "RAPIDS_REPOSITORY=${{ inputs.repo || github.repository }}" >> "${GITHUB_ENV}"
          echo "RAPIDS_SHA=$(git rev-parse HEAD)" >> "${GITHUB_ENV}"
          echo "RAPIDS_REF_NAME=${{ inputs.branch || github.ref_name }}" >> "${GITHUB_ENV}"
          echo "RAPIDS_NIGHTLY_DATE=${{ inputs.date }}" >> "${GITHUB_ENV}"
      - name: Python tests
        run: ${{ inputs.script }}
        env:
          GH_TOKEN: ${{ github.token }}
      - name: Generate test report
        uses: test-summary/action@v2.4
        with:
          paths: "${{ env.RAPIDS_TESTS_DIR }}/*.xml"
        if: always()
      - name: Run codecov
        if: inputs.run_codecov
        env:
          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}
        run: |
          codecovcli \
            -v \
            upload-process \
            -C ${{ github.sha }} \
            -s "${RAPIDS_COVERAGE_DIR}" \
            --handle-no-reports-found
      - name: Upload additional artifacts
        if: "!cancelled()"
        run: rapids-upload-artifacts-dir cuda${RAPIDS_CUDA_VERSION%%.*}_$(arch)_py${RAPIDS_PY_VERSION//.}
      - name: Telemetry summary
        id: telemetry-summary
        if: "always()"
        uses: rapidsai/shared-actions/telemetry-summarize@add-telemetry
        with:
          endpoint: ${{ inputs.traces_endpoint || inputs.default_endpoint && format('{0}/v1/traces', inputs.default_endpoint) }}
          traceparent: "${{ env.TOP_LEVEL_TRACEPARENT }}"