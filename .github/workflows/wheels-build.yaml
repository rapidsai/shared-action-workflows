name: Build RAPIDS wheels

on:
  workflow_call:
    inputs:
      # repo and branch
      repo:
        type: string
      branch:
        type: string
      date:
        type: string
      sha:
        type: string
      build_type:
        required: true
        type: string
      script:
        required: true
        type: string

      # allow a bigger runner instance
      node_type:
        required: false
        type: string
        default: "cpu16"

      # general settings
      matrix_filter:
        type: string
        default: "."

      # Extra repository that will be cloned into the project directory.
      extra-repo:
        required: false
        type: string
        default: ''
      extra-repo-sha:
        required: false
        type: string
        default: ''
      # Note that this is the _name_ of a secret containing the key, not the key itself.
      extra-repo-deploy-key:
        required: false
        type: string
        default: ''
      default_endpoint:
        type: string
        description: "Destination to send telemetry to, not including path like /v1/traces"
      traceparent:
        type: string
        description: |
            Opentelemetry traceparent. Format is described in https://medium.com/@mesutatasoy/understanding-traceparent-and-microservices-in-opentelemetry-notepad-series-7-de5c16bf6462
            Generally, 00-<trace_id 32 chars>-<span_id 16 chars>-01
      otel_resource_attributes:
        type: string
        description: |
          Comma-separated key=value pairs used for storing additional "tags" to better identify data
      shared_actions_repo:
        type: string
        description: git repo for rapidsai/shared-actions code
        default: rapidsai/shared-actions
      shared_actions_ref:
        type: string
        description: git ref of branch/tag/sha for rapidsai/shared-actions repo
        default: main

defaults:
  run:
    shell: bash

permissions:
  actions: read
  checks: none
  contents: read
  deployments: none
  discussions: none
  id-token: write
  issues: none
  packages: read
  pages: none
  pull-requests: read
  repository-projects: none
  security-events: none
  statuses: none

env:
  # TODO: this should be set as an org-wide variable
  OTEL_EXPORTER_OTLP_ENDPOINT: "${{ inputs.default_endpoint }}"
  OTEL_EXPORTER_OTLP_PROTOCOL: "http/protobuf"
  OTEL_PYTHON_DISABLED_INSTRUMENTATIONS: "jinja2"
  # OTEL_RESOURCE_ATTRIBUTES is set inside the matrix

jobs:
  compute-matrix:
    runs-on: ubuntu-latest
    outputs:
      MATRIX: ${{ steps.compute-matrix.outputs.MATRIX }}
    steps:
      - name: Compute Build Matrix
        id: compute-matrix
        run: |
          set -eo pipefail

          # please keep the matrices sorted in ascending order by the following:
          #
          #     [ARCH, PY_VER, CUDA_VER, LINUX_VER]
          #
          export MATRIX="
          # amd64
          - { ARCH: 'amd64', PY_VER: '3.10', CUDA_VER: '11.8.0', LINUX_VER: 'rockylinux8' }
          - { ARCH: 'amd64', PY_VER: '3.10', CUDA_VER: '12.5.1', LINUX_VER: 'rockylinux8' }
          - { ARCH: 'amd64', PY_VER: '3.11', CUDA_VER: '11.8.0', LINUX_VER: 'rockylinux8' }
          - { ARCH: 'amd64', PY_VER: '3.11', CUDA_VER: '12.5.1', LINUX_VER: 'rockylinux8' }
          - { ARCH: 'amd64', PY_VER: '3.12', CUDA_VER: '11.8.0', LINUX_VER: 'rockylinux8' }
          - { ARCH: 'amd64', PY_VER: '3.12', CUDA_VER: '12.5.1', LINUX_VER: 'rockylinux8' }
          # arm64
          - { ARCH: 'arm64', PY_VER: '3.10', CUDA_VER: '11.8.0', LINUX_VER: 'rockylinux8' }
          - { ARCH: 'arm64', PY_VER: '3.10', CUDA_VER: '12.5.1', LINUX_VER: 'rockylinux8' }
          - { ARCH: 'arm64', PY_VER: '3.11', CUDA_VER: '11.8.0', LINUX_VER: 'rockylinux8' }
          - { ARCH: 'arm64', PY_VER: '3.11', CUDA_VER: '12.5.1', LINUX_VER: 'rockylinux8' }
          - { ARCH: 'arm64', PY_VER: '3.12', CUDA_VER: '11.8.0', LINUX_VER: 'rockylinux8' }
          - { ARCH: 'arm64', PY_VER: '3.12', CUDA_VER: '12.5.1', LINUX_VER: 'rockylinux8' }
          "

          MATRIX="$(
            yq -n -o json 'env(MATRIX)' | \
            jq -c '${{ inputs.matrix_filter }} | if (. | length) > 0 then {include: .} else "Error: Empty matrix\n" | halt_error(1) end'
          )"

          echo "MATRIX=${MATRIX}" | tee --append "${GITHUB_OUTPUT}"
  build:
    name:  ${{ matrix.CUDA_VER }}, ${{ matrix.PY_VER }}, ${{ matrix.ARCH }}, ${{ matrix.LINUX_VER }}
    needs: [compute-matrix]
    strategy:
      matrix: ${{ fromJSON(needs.compute-matrix.outputs.MATRIX) }}
    runs-on: "linux-${{ matrix.ARCH }}-${{ inputs.node_type }}"
    env:
      RAPIDS_ARTIFACTS_DIR: ${{ github.workspace }}/artifacts
      # TODO: set operation name somehow # rapids.operation=${{inputs.OTEL_SERVICE_NAME_PREFIX}}
      OTEL_RESOURCE_ATTRIBUTES: "${{inputs.otel_resource_attributes}},rapids.operation=build,rapids.package_type=wheel,rapids.cuda=${{matrix.CUDA_VER}},rapids.py=${{matrix.PY_VER}},rapids.arch=${{matrix.ARCH}},rapids.linux=${{matrix.LINUX_VER}}"
    container:
      image: "rapidsai/ci-wheel:cuda${{ matrix.CUDA_VER }}-${{ matrix.LINUX_VER }}-py${{ matrix.PY_VER }}"
      env:
        RAPIDS_BUILD_TYPE: ${{ inputs.build_type }}

    steps:
      - uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ vars.AWS_ROLE_ARN }}
          aws-region: ${{ vars.AWS_REGION }}
          role-duration-seconds: 43200 # 12h

      - name: checkout code repo
        uses: actions/checkout@v4
        with:
          repository: ${{ inputs.repo }}
          ref: ${{ inputs.sha }}
          fetch-depth: 0 # unshallow fetch for setuptools-scm
          persist-credentials: false

      - name: Checkout actions
        uses: actions/checkout@v4
        with:
            repository: ${{inputs.shared_actions_repo}}
            ref: ${{inputs.shared_actions_ref}}
            path: ./shared-actions

      - name: Standardize repository information
        uses: ./shared-actions/rapids-github-info
        with:
          repo: ${{ inputs.repo }}
          branch: ${{ inputs.branch }}
          date: ${{ inputs.date }}
          sha: ${{ inputs.sha }}

      - name: Preprocess extra repos
        id: preprocess-extras
        if: ${{ inputs.extra-repo != '' }}
        run: |
          EXTRA_REPO_PATH=$(echo ${{ inputs.extra-repo }} | cut -d "/"  -f 2)
          echo "EXTRA_REPO_PATH=${EXTRA_REPO_PATH}" >> $GITHUB_OUTPUT

      - name: checkout extra repos
        uses: actions/checkout@v4
        if: ${{ inputs.extra-repo != '' }}
        with:
          repository: ${{ inputs.extra-repo }}
          ref: ${{ inputs.extra-repo-sha }}
          path: "./${{ steps.preprocess-extras.outputs.EXTRA_REPO_PATH }}"
          ssh-key: ${{ secrets[inputs.extra-repo-deploy-key] }}
          persist-credentials: false

      - name: Get GitHub job info, to obtain machine info
        uses: ./shared-actions/github-actions-job-info
        id: job-info
      - name: Add machine details to attributes metadata
        run: |
          labels=$(echo "${{steps.job-info.outputs.job-info}}" | jq -r '.labels | join(" ")')
          echo OTEL_RESOURCE_ATTRIBUTES="${OTEL_RESOURCE_ATTRIBUTES},rapids.labels=${labels}"  >> ${GITHUB_ENV}

      - name: Telemetry setup
        id: job-traceparent
        uses: ./shared-actions/telemetry-traceparent

      - name: Build and repair the wheel
        run: |
          ${{ inputs.script }}
        env:
          GH_TOKEN: ${{ github.token }}
        # Use a shell that loads the rc file so that we get the compiler settings
        shell: bash -leo pipefail {0}
      - name: Upload additional artifacts
        if: "!cancelled()"
        run: rapids-upload-artifacts-dir cuda${RAPIDS_CUDA_VERSION%%.*}_$(arch)_py${RAPIDS_PY_VERSION//.}
      - name: Telemetry summary
        id: telemetry-summary
        if: "always()"
        uses: ./shared-actions/telemetry-summarize
        with:
          traceparent: "${{ inputs.traceparent }}"
          ca_cert: "${{secrets.OTEL_EXPORTER_OTLP_CA_CERTIFICATE}}"
          client_cert: "${{secrets.OTEL_EXPORTER_OTLP_CLIENT_CERTIFICATE}}"
          client_key: "${{secrets.OTEL_EXPORTER_OTLP_CLIENT_KEY}}"
